# pip install sentence-transformers numpy scikit-learn

import numpy as np
import glob
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import logging
import os
import time
from corpora import CORPORA_FILES

# Ustawienie logowania
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

# --- KONFIGURACJA CIE呕EK I PARAMETRW ---
MODEL_NAME = 'sdadas/st-polish-paraphrase-from-distilroberta' 
OUTPUT_EMBEDDINGS_FILE = "sbert_sentence_embeddings.npy"

files = CORPORA_FILES["ALL"]

# --- ETAP 1: Wczytanie Korpusu ---

def load_raw_sentences(file_list):
    """Wczytuje surowe zdania z listy plik贸w."""
    raw_sentences = []
    print(f"Wczytywanie tekstu z {len(file_list)} plik贸w...")
    for file in file_list:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                # Wczytaj linie, usu biae znaki i pomi puste
                lines = [line.strip() for line in f if line.strip()]
                raw_sentences.extend(lines)
        except FileNotFoundError:
            # Ostrze偶enie, jeli plik nie zostanie znaleziony
            print(f"OSTRZE呕ENIE: Nie znaleziono pliku '{file}'. Pomijam.")
        except Exception as e:
            print(f"BD podczas przetwarzania pliku '{file}': {e}")

    if not raw_sentences:
        raise ValueError("Korpus danych jest pusty lub nie zosta wczytany.")
    
    return raw_sentences

try:
    raw_sentences = load_raw_sentences(files)
    print(f"Wczytano {len(raw_sentences)} zda do przetworzenia.")
except ValueError as e:
    print(f"BD: {e}")
    exit()

# --- ETAP 2: Generowanie/Wczytywanie Embedding贸w KORPUSU ---

# Sprawdzenie, czy wektory korpusu istniej ju偶 na dysku
if os.path.exists(OUTPUT_EMBEDDINGS_FILE):
    # --- Wariant 1: Wczytywanie z pliku (.npy) ---
    print(f"\n--- Wariant 1: Wczytywanie wektor贸w z pliku '{OUTPUT_EMBEDDINGS_FILE}' ---")
    try:
        start_time = time.time()
        sentence_embeddings = np.load(OUTPUT_EMBEDDINGS_FILE)
        end_time = time.time()
        print(f"Wektory zaadowane pomylnie w {end_time - start_time:.2f} sekundy. Pominito kodowanie.")
        
    except Exception as e:
        # W przypadku bdu wczytywania (np. uszkodzony plik), przejd藕 do generowania
        print(f"BD podczas adowania pliku .npy: {e}. Przetwarzam korpus od nowa.")
        needs_generation = True
    else:
        needs_generation = False
else:
    needs_generation = True

if needs_generation:
    # --- Wariant 2: adowanie Modelu i Generowanie ---
    print(f"\n--- Wariant 2: adowanie Modelu i Generowanie Wektor贸w ---")
    print(f"adowanie Sentence-Transformer: {MODEL_NAME}...")
    try:
        # Wczytanie modelu z Hugging Face
        model_sbert = SentenceTransformer(MODEL_NAME)
    except Exception as e:
        print(f"FATALNY BD podczas adowania modelu {MODEL_NAME}: {e}")
        exit()

    print(f"Generowanie wektor贸w dla {len(raw_sentences)} zda...")
    start_time = time.time()
    # Metoda .encode() automatycznie tokenizuje i generuje wektory
    sentence_embeddings = model_sbert.encode(
        raw_sentences, 
        show_progress_bar=True,
        convert_to_numpy=True
    )
    end_time = time.time()
    print(f"Generowanie zakoczone w {end_time - start_time:.2f} sekundy.")
    
    # Zapisanie nowo utworzonych wektor贸w do pliku
    np.save(OUTPUT_EMBEDDINGS_FILE, sentence_embeddings)
    print(f"Wektory zda zapisane jako: '{OUTPUT_EMBEDDINGS_FILE}'.")


print(f"\nKsztat macierzy embedding贸w zda: {sentence_embeddings.shape}")
print(f"Wymiar wektora zdania: {sentence_embeddings.shape[1]}")


# --- ETAP 3: Przykadowe Wykorzystanie (Por贸wnywanie Zda) ---

# =========================================================
# === DODANY FRAGMENT KODU ROZWIZUJCY BD NameError ===
# =========================================================
# Sprawdzenie, czy model zosta ju偶 zainicjowany (tj. czy zmienna istnieje w globalnym zakresie)
if 'model_sbert' not in locals() and 'model_sbert' not in globals():
    print(f"\nadowanie Sentence-Transformer do kodowania zapytania: {MODEL_NAME}...")
    try:
        model_sbert = SentenceTransformer(MODEL_NAME)
        print("Model SBERT zaadowany pomylnie.")
    except Exception as e:
        print(f"BD podczas adowania modelu dla zapytania: {e}")
        exit()
# =========================================================
# ヰヰヰヰヰtestowanie zdaヰヰヰヰヰヰヰ
query_sentence = "Jestem godny."
# query_sentence = "Wojsko wejdzie do miast i skocz si bunty"
# query_sentence = "Leczenie tego schorzenia jest bardzo wa偶ne i wymaga interwencji lekarza."
print(f"\n--- Wyszukiwanie podobiestwa do: '{query_sentence}' ---")

# Generowanie wektora dla zapytania
query_embedding = model_sbert.encode(
    [query_sentence], 
    convert_to_numpy=True
)

# Obliczenie podobiestwa kosinusowego midzy zapytaniem a wszystkimi zdaniami
# Podobiestwo kosinusowe jest standardow miar podobiestwa wektor贸w
similarities = cosine_similarity(query_embedding, sentence_embeddings)[0]

# Wyszukanie 5 najbardziej podobnych
top_5_indices = np.argsort(similarities)[::-1][:5]

print("\n5 zda z korpusu najbardziej podobnych do zapytania:")
for i in top_5_indices:
    print(f"  - Sim: {similarities[i]:.4f} | Zdanie: {raw_sentences[i]}")

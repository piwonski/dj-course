# Zadanie 1

Jailbreaking.
Sprowokuj wybranego LLMa (moÅ¼e lepiej lokalnego, aby "nie naruszaÄ‡ zasad" dostawcÃ³w zewn.) do wykonania akcji niedozwolonej.

SzczegÃ³Å‚y omÃ³wione w lekcji "praca domowa".

PrzykÅ‚ady/inspiracje: `M2/jailbreaking`.

**CEL**: osiÄ…gniÄ™cie min. 1 skutecznego jailbreaka.

# Zadanie 2

Syntezacja mowy: **TEXT-TO-SPEECH**

BezpoÅ›rednio poniÅ¼ej techniczny opis - zaÅ› sam opis ZADAÅƒ jest w punktach 2.1 i 2.2 niÅ¼ej.

przygotowane/uÅ¼ywane syntezatory:
- suno:
  - `text-to-speach-suno-bark`, `python run.py`
  - sÅ‚absze jakoÅ›ciowo (output zaszumiony)
- xtts
  - `text-to-speach-xtts`, `python run.py`
  - lepsze jakoÅ›ciowo
  - obsÅ‚uguje de facto wiele modeli pod spodem (komenda: `tts --list_models`, oczywiÅ›cie majÄ…c zainstalowane zaleÅ¼noÅ›ci, np. w venvie)
  - wymaga pythona max 3.12 (z 3.13+ nie pÃ³jdzie)
    - polecane `pyenv`, dziaÅ‚ajÄ…ce bardzo podobnie do `nvm`/node.js
    - nie znasz `pyenv`? Super - poproÅ› LLMa o wygenerowanie tutoriala dla Ciebie, np.
    > wygeneruj podstawowy tutorial uczÄ…cy jak wykorzystywaÄ‡ pyenv. Mam zainstalowanego globalnie pythona 3.13 - i chcÄ™ dodatkowo mieÄ‡ pythona 3.12 ale nie globalnie. I dla tego pythona stworzyÄ‡ virtualenv (`.venv`) w ktÃ³rym bÄ™dÄ… moje zaleÅ¼noÅ›ci. Wygeneruj wszystkie potrzebne komendy, kaÅ¼da z krÃ³tkim opisem co robi i dlaczego jest potrzebna.
    ale dostosuj go do siebie, np. doprecyzuj system operacyjny (i cokolwiek, czego jeszcze potrzebujesz)

uruchom syntezator suno/bark:
- albo lokalnie
- albo z google colab: https://colab.research.google.com/drive/1hIsAmSCaiR_mo_BggjHRGNoi9z4WO0P6?usp=sharing

uruchom xtts:
- albo lokalnie
- albo z google colab. I jeÅ›li chcesz - sprÃ³buj samodzielnie przygotowaÄ‡ colaba. JeÅ›li siÄ™ zdecydujesz, to - waÅ¼ne:
  - ustaw ÅšRODOWISKO (Å¼eby bazowaÅ‚ nie na CPU-only tylko np. `GPU T4` lub `v5e-1 TPU` - ustawienia / **ZmieÅ„ typ Å›rodowiska wykonawczego**). Chodzi, tylko albo aÅ¼, o czas.
  - upewnij siÄ™ co do wersji pythona w collabie. W momencie tworzenia materiaÅ‚u jest to wersja 3.12.12, ale hipotetycznie domyÅ›lna wersja moÅ¼e siÄ™ zmieniÄ‡. WÃ³wczas - sprawdÅº wersjÄ™:
  ```
  !python --version
  ```
  wykrzyknik jest kluczowy i oznacza uruchomienie kodu nie pythonowego - tylko w powÅ‚oce serwera collaba (tak samo ma jupyter).
  I w razie potrzeby - instalujesz oczekiwanÄ… wersjÄ™:
  ```
  !apt-get install python3.12
  !python3.12 --version
  ```
  i tyle :)

docs:
- suno: https://github.com/suno-ai/bark
- xtts: https://github.com/coqui-ai/TTS

**Bazowy kod jest gotowy do uruchomienia**.

## Zadanie 2.1

Uruchom wybrany model **text-to-speech**. Rekomendowane: xtts (suno/bark daje mocno zaszumiony output). JeÅ›li wybierzesz xtts - daj swojÄ… prÃ³bkÄ™ gÅ‚osu, aby wygenerowaÄ‡ syntetycznie TwojÄ… mowÄ™.

**CEL**: uruchomiÅ‚eÅ›/aÅ› syntezator lokalnie

## Zadanie 2.2

Do AZÃ˜RA (asystenta czatowego) dodaj nowÄ… komendÄ™, np. `/audio` ktÃ³ra wygeneruje dÅºwiÄ™k ostatniej odpowiedzi AZÃ˜RA jako plik dÅºwiÄ™kowy.

**CEL**: AZÃ˜R moÅ¼e do Ciebie mÃ³wiÄ‡ (szczekaÄ‡?) dziÄ™ki nowej komendzie.

## Zadanie 2.3 (dla chÄ™tnych)

Wykorzystaj tekst zarÃ³wno Twojego prompta jak i odpowiedzi modelu (AZÃ˜RA) aby wygenerowaÄ‡ spÃ³jny dialog - w oparciu o historiÄ™ konwersacji, ktÃ³rÄ… regularnie prowadzisz z asystentem czatowym.

Wykorzystujesz pod spodem ten sam syntezator (xtts), ale przekazujesz mu **inne sample** (aby daÅ‚o siÄ™ odrÃ³Å¼niÄ‡ rozmÃ³wcÃ³w).

Do Å‚Ä…czenia wielu plikÃ³w .wav w 1 - wykorzystaj **dowolnÄ…** bibliotekÄ™ (np. `audiolab`, `scipy`, `wave`), posiÅ‚kuj siÄ™ LLMami w celu pomocy z kodem. Rekomendacja - DIVIDE AND CONQUER (problem rozbij na mniejsze):
- w pierwszym kroku wygeneruj dziaÅ‚ajÄ…cy mini-skrypt ktÃ³ry poprawnie obsÅ‚uÅ¼y API i poÅ‚Ä…czy 2 pliki wav w 1. (tu posiÅ‚kuj siÄ™ deep researchem - no chyba Å¼e TwÃ³j agent kodujÄ…cy ma zapewniony dostÄ™p do internetu np. na poziomie "server tool calls")
- dopiero potem - w oparciu o dziaÅ‚ajÄ…ce API, zleÄ‡ agentowi kodujÄ…cemu integracjÄ™ kodu z AZÃ˜REM)

**CEL**:
- prowadzisz konwersacjÄ™
- uruchamiasz nowÄ… komendÄ™ np. `/audio-all`
- generuje siÄ™ caÅ‚a dotychczasowa konwersacja jako .wav

# Zadanie 3

Transkrypcja mowy: **SPEECH-TO-TEXT**

Wykorzystujemy model: `openai/whisper-tiny` (ok. 150MB miejsca, lekki) ale moÅ¼esz podmieniÄ‡ (zachÄ™cam do eksperymentÃ³w) na jakiÅ› model wiÄ™kszy (lista tu: https://huggingface.co/collections/openai/whisper-release)

Bazowy kod zarÃ³wno w `M2/transcriber` jak i `M2/transcriber-ui` - dziaÅ‚a.

# Zadanie 3.1

Uruchamiasz lokalnie kod `M2/transcriber`. WykorzystujÄ…c przygotowane wczeÅ›niej sample z folderu `M2/sample-audio` otrzymujesz transkrypcjÄ™ tekstowÄ….

# Zadanie 3.2

Wykorzystujesz `M2/transcriber-UI`, ktÃ³re jest zbudowane w tkinter - pythonowym desktopowym GUI (pamiÄ™ta ktoÅ› Java Swing?).

Aplikacja dziaÅ‚a.

**ZADANIE**: dodaÄ‡ 2 zakÅ‚adki (na wzÃ³r superwhisper/czegokolwiek):
- jedna przedstawia historiÄ™ transkrypcji, czyli pojedynczych "uruchomieÅ„" transkrypcji wraz z tekstem wynikowym (w dowolnej formie)
- moÅ¼liwoÅ›Ä‡ usuwania pojedynczej transkrypcji
- wymaganie - program przechowuje swoje dane "gdzieÅ›" w formie i plikÃ³w .wav i .json. ZarzÄ…dzanie transkrypcjami ma byÄ‡ odzwierciedlane w plikach (tworzone/usuwane) - aby byÅ‚o spÃ³jnie

Zapewne nie znasz tkintera (byÅ‚oby dziwne gdybyÅ› znaÅ‚(a)) - i o to chodzi. DziaÅ‚aj z kodujÄ…cym agentem.

**Rekomendacja**: dobrze przemyÅ›l, co ma byÄ‡ zbudowane, jak UI ma siÄ™ zachowywaÄ‡. Po prostu wymyÅ›l szczegÃ³Å‚y UI-a - jak ma wyglÄ…daÄ‡. I dopiero pisz prompty.

# ALTERNATYWNIE 3.2

JeÅ›li nie chcesz (nie lubisz) tkintera (bo jest to technologia niszowa i maÅ‚o kto jÄ… zna), moÅ¼esz zbudowaÄ‡ swojÄ… aplikacjÄ™ desktopowÄ… o zupeÅ‚nie inny stos, np.
- wails:
  - backend: go, frontend: cokolwiek
  - https://wails.io/
- tauri:
  - backend: rust, frontend: cokolwiek
  - https://v2.tauri.app/

przy czym - do obsÅ‚ugi `openai/whisper-tiny` - i tak bÄ™dziesz potrzebowaÄ‡ pythonowego `transformers`. WÃ³wczas go/rust uruchamia transformers jako skrypt z shella, ktÃ³ry zwyczajnie koÅ„czy siÄ™ (1) utworzeniem pliku i (2) zwraca kod wynikowy z powÅ‚oki (kaÅ¼da komenda konsoowa zwraca kod; jeÅ›li kod=0 - jest ok, nie-0 - jakiÅ› bÅ‚Ä…d).

Natomiast complexity zwiÄ…zane z uruchamianiem serwera go/rust ktÃ³ry dopiero uruchamia pythona - znika, jeÅ›li wykorzystasz tkintera.

# Zadanie 4

`Toon` (Token-Oriented Object Notation)
https://github.com/toon-format/toon

Tokenizujemy pliki - analogicznie jak w poprzednim module, ale tym razem: `JSON`, `YAML` i `TOON`:
- do dyspozycji mamy rÃ³Å¼ne tokenizery `M2/toon/tokenizers/*.json`
- do dyspozycji mamy sample files w `M2/toon/samples`, gdzie kaÅ¼dy sample jest 4 formatach: `.json`, `-nows.json` (no whitespace), `.yaml`, `.noon`

Inicjalny skrypt `M2/toon/tokenize-json-toon.py` tokenizuje 1 tokenizerem 1 peÅ‚ny sample (4 pliki o rÃ³Å¼nych formatach).

JeÅ›li dodasz dowolny poprawny JSON, to uruchom `gen-from-json.py` (dodajÄ…c tam nazwÄ™ tego JSONa) i wygeneruje Ci pozostaÅ‚e 3 formaty (z `.json` - wygeneruje: `-nows.json`, `.yaml`, `.noon`). `noon` jest uruchamiane poprzez `npx` (wymagany node.js), bo w momencie publikacji paczka https://github.com/toon-format/toon-python jest WIP.

## Zadanie 4.1

**ZADANIE**:
- kaÅ¼dy sample to de facto 4 pliki (inne formaty ale majÄ… tÄ™ samÄ… treÅ›Ä‡)
- uruchom tokenizacjÄ™ dla wszystkich sampli (i ich 4 formatÃ³w)
- to samo uruchom dla udostÄ™pnionych tokenizerÃ³w
- stwÃ³rz wizualne zestawienie wynikÃ³w
- moÅ¼esz wskazaÄ‡, o ile toon wychodzi oszczÄ™dniej w tokenach
- dla chÄ™tnych:
  - bierzesz pythonowe [openAI/tiktoken](https://github.com/openai/tiktoken) i dokonujesz praktycznie to samo (tokenizacja) ale siÅ‚Ä… rzeczy ta libka ma inne API.

**OPCJE**:
- konsolowo: `tokenize-json-toon.py`
- przy uÅ¼yciu `marimo` (nowoczeÅ›niejsza i znacznie lepsza wersja `jupyter`)
  - uruchamiasz `marimo edit` (w venv, w folderze zadania)
  - otwiera siÄ™ automatycznie okno w przeglÄ…darce
  - przeklikujesz do pliku `tokenize-marimo.py` i masz marimo-notebook
  - (note: nie bÃ³j siÄ™ marimo, to po prostu odÅ›wieÅ¼ony jupyter: https://github.com/marimo-team/marimo)

Pliki majÄ… logicznie tÄ™ samÄ… treÅ›Ä‡.

## Zadanie 4.2

SprÃ³buj przedstawiÄ‡ dane w formie quasi-konsolowego-wykresu tak jak poniÅ¼ej (chodzi tylko o formÄ™ prezentacji):

```
arch
â†’ JSON compact   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    100.0% (2858)
  TOON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘     99.1% (2883)
  YAML           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘     94.7% (3019)
  JSON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘     54.2% (5270)

placeholder
â†’ TOON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    100.0% (110)
  JSON compact   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘     83.3% (132)
  YAML           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘     80.0% (114)
  JSON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘     73.3% (150)

recipe
â†’ TOON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    100.0% (1182)
  YAML           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘     89.1% (1326)
  JSON compact   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘     72.6% (1629)
  JSON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘     48.8% (2420)

models
â†’ TOON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    100.0% (349)
  YAML           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘     72.6% (481)
  JSON compact   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘     52.0% (671)
  JSON           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘     33.8% (1033)
```

albo:

```
arch
â†’ JSON compact   ####################    100.0% (2858)
  TOON           ##################..     99.1% (2883)
  YAML           ################....     94.7% (3019)
  JSON           #########...........     54.2% (5270)

placeholder
â†’ TOON           ####################    100.0% (110)
  JSON compact   ##################..     83.3% (132)
  YAML           ################....     80.0% (114)
  JSON           ############........     73.3% (150)

recipe
â†’ TOON           ####################    100.0% (1182)
  YAML           ##################..     89.1% (1326)
  JSON compact   ##############......     72.6% (1629)
  JSON           ############........     48.8% (2420)

models
â†’ TOON           ####################    100.0% (349)
  YAML           ################....     72.6% (481)
  JSON compact   ##############......     52.0% (671)
  JSON           ############........     33.8% (1033)
```

# Zadanie 5

Research codebase przy uÅ¼yciu [code2tutorial](https://code2tutorial.com/).

Wykorzystaj jakieÅ› wÅ‚asne repo (a jeÅ›li takowego nie masz, to stwÃ³rz wÅ‚asne i zuploaduj do niego AZÃ˜RA) - i kaÅ¼ code2tutorial wygenerowaÄ‡ raport, ktÃ³ry opisuje zawartoÅ›Ä‡/strukturÄ™ repo.

W zaÅ‚oÅ¼eniu powinno generowaÄ‡ przejrzystÄ… dokumentacÄ™/raport. W praktyce - bywa rÃ³Å¼nie ;) raz lepiej, raz gorzej. Automat Â¯\_(ãƒ„)_/Â¯

## Zadanie 5.1

**ZADANIE**: po prostu odpal to narzÄ™dzie :) i przejrzyj output

# Zadanie 5.2

**Zaprojektuj** (NIE IMPLEMENTUJ bo to za duÅ¼o pracy) jak tej klasy narzÄ™dzie dziaÅ‚a pod spodem. Co robi agent/orkiestrator? Jak wyglÄ…da komunikacja (przepÅ‚yw, np. diagramy sekwencji)? Jak wyglÄ…da ruch sieciowy? Jak sÄ… montowane dane?

**CEL**: dowolne diagramy, opis tekstowy raczej (bardzo) krÃ³ki.

**PO CO**? UmiejÄ™tnoÅ›Ä‡ projektowania jest KLUCZOWA w rozwoju.

# Zadanie 6

AZÃ˜R - Nadaj tytuÅ‚ wÄ…tkowi
(rozbuduj AZÃ˜RA z kodu bazowego z `M1/azor-chatdog-*`)

Najpierw ZAPROJEKTUJ - potem ZAKODUJ ficzer ktÃ³ry umoÅ¼liwia AZÃ˜ROWI tytuÅ‚owanie wÄ…tkÃ³w (konwersacji) podczas ich tworzenia.

W typowych aplikacjach konwersacyjnych dziaÅ‚a to tak:
- otwierasz nowy wÄ…tek, piszesz prompta
- otrzymujesz odpowiedÅº (obviously)
- wÄ…tek jest domyÅ›lnie TYTUÅOWANY na podstawie Twojego pierwszego prompta
- moÅ¼esz potem wÄ…tek "przenazwiÄ‡", ale wyÅ‚Ä…cznie rÄ™cznie. Automatyczne nazywanie wÄ…tku dzieje siÄ™ tylko przy pierwszym prompcie.

**ZADANIE 6.1**:
- najpierw **PRZEMYÅšL** jak to zrobiÄ‡. Omawiaj na discordzie pomysÅ‚y. RÃ³Å¼nych rozwiÄ…zaÅ„ jest sporo, sÄ… lepsze i gorsze, prostsze i trudniejsze

**ZADANIE 6.2**:
- **ZAIMPLEMENTUJ**. Obecnie wÄ…tki moÅ¼na identyfikowaÄ‡ jedynie po ID sesji i - o ile w przypadku przeÅ‚Ä…czania wÄ…tku to musi zostaÄ‡ - o tyle wyÅ›wietlenie tytuÅ‚u wÄ…tku (wraz z jego wczeÅ›niejszym ustaleniem) byÅ‚oby bardzo user-friendly.
- TytuÅ‚owanie wÄ…tku dzieje siÄ™ z automatu. JeÅ›li powstaje wÄ…tek (wysÅ‚aÅ‚eÅ›/aÅ› prompta), to musi byÄ‡ zatytuÅ‚owany
- TytuÅ‚ wÄ…tku jest (siÅ‚Ä… rzeczy) przechowywany w plikach `.json`, dla spÃ³jnoÅ›ci systemu (persystencja)
- TytuÅ‚ moÅ¼na zmieniÄ‡ (np. w oparciu o nowÄ… komendÄ™ `/session rename NEW_TITLE` )
- TytuÅ‚ moÅ¼na teÅ¼ podejrzeÄ‡ dla aktualnego wÄ…tku/sesji (np. w oparciu o nowÄ… komendÄ™ `/session title` -> `EXISTING_TITLE` )

# Zadanie 7

AZÃ˜R - Wyspecjalizowani asystenci
(rozbuduj AZÃ˜RA z kodu bazowego z `M1/azor-chatdog-*`)

- kodujesz moÅ¼liwoÅ›Ä‡ tworzenia rÃ³Å¼nych **wyspecjalizowanych asystentÃ³w**.
- uÅ¼ytkownik przeÅ‚Ä…cza asystenta manualnie, np. nowÄ… komendÄ…
- asystenci mogÄ… byÄ‡ zahardkodowani w kodzie (choÄ‡ moÅ¼na zaprogramowaÄ‡ tworzenie nowych dynamicznie np. nowÄ… komendÄ…)
- WÄ…tek (sesja) powinien mieÄ‡ okreÅ›lonego aktualnego asystenta (aby byÅ‚o spÃ³jnie i jednoznacznie)
  - zapisujÄ…c sesjÄ™, zapisywana jest nie tylko historia konwersacji, ale i asystent
  - Å‚Ä…dujÄ…c starÄ… sesjÄ™ - analogicznie
  - zmiana asystenta w trakcie sesji zostawia Å›laj w historii konwersacji, aby model w nastÄ™pnych krokach wiedziaÅ‚, Å¼e zmiana miaÅ‚a miejsce (wÃ³wczas na podst. system prompta lepiej ogarnie kontekst)

**CEL**: masz minimum 2 nowych asystentÃ³w (a AZÃ˜R zostaje - wiÄ™c w sumie minimum trzech). I w moÅ¼esz w trakcie trwania konwersacji ich przeÅ‚Ä…czaÄ‡.

**Inspiracje asystentÃ³w**:
- perfekcjonista przykÅ‚adajÄ…cy ogromnÄ… wagÄ™ do detali.
- biznesmen zorientowany na cele, wypowiadajÄ…cy siÄ™ bardzo rzeczowo i krÃ³tko.
- optymistyczny pochlebca ktÃ³ry zawsze pocieszy i dopytuje jak siÄ™ czujesz.
ale to moÅ¼e byÄ‡ co-/ktokolwiek.

# Zadanie 8

TEXT-TO-SONG ;)

- Wskakuj na suno.com
- Korzystasz z darmowego planu
  - 50 kredytÃ³w oznacza de facto 5 Å¼Ä…daÅ„
  - jeÅ›li masz jakieÅ› "robocze" konta, to tym wiÄ™cej bÄ™dziesz mieÄ‡ kredytÃ³w ğŸ§…
- Przygotowujesz tekst utworu muzycznego (inspiracje znajdziesz w `M2/text-to-song`) ale Å›miaÅ‚o zachÄ™cam do twÃ³rczoÅ›ci - czy to z LLMami, czy wÅ‚asnej
- Generujesz ğŸµ utwory ğŸ¶
- Rezultaty wrzucasz na discorda na kafaÅ‚ `#ai-music-corner` :)

W suno:
- zakÅ‚adka `CREATE`
- wklejasz **lyrics** (no chyba Å¼e chcesz instrumental - to wtedy napisz np. `[instrumental]`, `[no lyrics]`, w przeciwnym razie sam jakiÅ› tekst naklepie)
- klejasz **style** - tu wstawiasz nie tylko gatunki muzyczne, ale wszelkie detale typu "bells", "screaming", "fast", "slow", "gentle", co kto lubi

**CEL**: MIEÄ† Z TEGO RADOÅšÄ† I DOBRÄ„ ZABAWÄ˜ ğŸ˜
